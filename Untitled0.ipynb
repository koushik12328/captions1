{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPlNuybxssC7BAgu8fJJvPl",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/koushik12328/captions1/blob/main/Untitled0.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j1HzPitMXB6C",
        "outputId": "a2e38550-cc20-459b-d1ed-fd15bf4d80fb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üöÄ Installing CaptionCrafter AI Dependencies...\n",
            "======================================================================\n",
            "\u001b[2K     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m803.2/803.2 kB\u001b[0m \u001b[31m6.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for openai-whisper (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "‚úÖ All dependencies installed!\n",
            "======================================================================\n",
            "‚ö†Ô∏è  No GPU available, using CPU (will be slower)\n",
            "======================================================================\n"
          ]
        }
      ],
      "source": [
        "# ============================================================================\n",
        "# CELL 1: Installation & Setup\n",
        "# ============================================================================\n",
        "\n",
        "print(\"üöÄ Installing CaptionCrafter AI Dependencies...\")\n",
        "print(\"=\" * 70)\n",
        "\n",
        "# Install core dependencies\n",
        "!pip install -q openai-whisper\n",
        "!pip install -q transformers sentencepiece\n",
        "!pip install -q torch torchvision torchaudio\n",
        "!pip install -q moviepy\n",
        "!pip install -q ffmpeg-python\n",
        "!pip install -q gradio  # For web UI\n",
        "\n",
        "# Install system dependencies\n",
        "!apt-get -qq install -y ffmpeg\n",
        "\n",
        "print(\"‚úÖ All dependencies installed!\")\n",
        "print(\"=\" * 70)\n",
        "\n",
        "# Check GPU availability\n",
        "import torch\n",
        "if torch.cuda.is_available():\n",
        "    print(f\"üéÆ GPU Available: {torch.cuda.get_device_name(0)}\")\n",
        "    print(f\"üíæ GPU Memory: {torch.cuda.get_device_properties(0).total_memory / 1e9:.2f} GB\")\n",
        "else:\n",
        "    print(\"‚ö†Ô∏è  No GPU available, using CPU (will be slower)\")\n",
        "print(\"=\" * 70)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================================================\n",
        "# CELL 2: Import Required Libraries\n",
        "# ============================================================================\n",
        "\n",
        "import whisper\n",
        "import os\n",
        "import torch\n",
        "import json\n",
        "from datetime import timedelta\n",
        "from moviepy.editor import VideoFileClip\n",
        "import ffmpeg\n",
        "from transformers import MarianMTModel, MarianTokenizer\n",
        "from IPython.display import display, HTML, Video, Audio\n",
        "import gradio as gr\n",
        "from google.colab import files\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "print(\"‚úÖ Libraries imported successfully\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Bxz7Y85EXk5E",
        "outputId": "ae4e0b86-df86-4f2c-f538-c58afffd82dd"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/moviepy/config_defaults.py:47: SyntaxWarning: invalid escape sequence '\\P'\n",
            "  IMAGEMAGICK_BINARY = r\"C:\\Program Files\\ImageMagick-6.8.8-Q16\\magick.exe\"\n",
            "/usr/local/lib/python3.12/dist-packages/moviepy/video/io/ffmpeg_reader.py:294: SyntaxWarning: invalid escape sequence '\\d'\n",
            "  lines_video = [l for l in lines if ' Video: ' in l and re.search('\\d+x\\d+', l)]\n",
            "/usr/local/lib/python3.12/dist-packages/moviepy/video/io/ffmpeg_reader.py:367: SyntaxWarning: invalid escape sequence '\\d'\n",
            "  rotation_lines = [l for l in lines if 'rotate          :' in l and re.search('\\d+$', l)]\n",
            "/usr/local/lib/python3.12/dist-packages/moviepy/video/io/ffmpeg_reader.py:370: SyntaxWarning: invalid escape sequence '\\d'\n",
            "  match = re.search('\\d+$', rotation_line)\n",
            "WARNING:py.warnings:/usr/local/lib/python3.12/dist-packages/moviepy/video/io/sliders.py:61: SyntaxWarning: \"is\" with 'str' literal. Did you mean \"==\"?\n",
            "  if event.key is 'enter':\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ Libraries imported successfully\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================================================\n",
        "# CELL 3: Multilingual Transcriber\n",
        "# ============================================================================\n",
        "\n",
        "class MultilingualTranscriber:\n",
        "    \"\"\"Transcribe audio/video in multiple languages using Whisper\"\"\"\n",
        "\n",
        "    SUPPORTED_LANGUAGES = {\n",
        "        'en': 'English', 'hi': 'Hindi', 'es': 'Spanish',\n",
        "        'fr': 'French', 'de': 'German', 'ja': 'Japanese',\n",
        "        'ko': 'Korean', 'zh': 'Chinese', 'ar': 'Arabic',\n",
        "        'ru': 'Russian', 'pt': 'Portuguese', 'it': 'Italian'\n",
        "    }\n",
        "\n",
        "    def __init__(self, model_name='base'):\n",
        "        \"\"\"\n",
        "        Initialize Whisper model\n",
        "        Options: tiny, base, small, medium, large\n",
        "        Recommended for Colab: base or medium\n",
        "        \"\"\"\n",
        "        print(f\"üîÑ Loading Whisper '{model_name}' model...\")\n",
        "        self.model = whisper.load_model(model_name)\n",
        "        self.device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "        self.model = self.model.to(self.device)\n",
        "        print(f\"‚úÖ Model loaded on {self.device}\")\n",
        "\n",
        "    def transcribe(self, audio_path, language=None, word_timestamps=True):\n",
        "        \"\"\"Transcribe audio with optional language specification\"\"\"\n",
        "        print(f\"üéß Transcribing: {os.path.basename(audio_path)}\")\n",
        "\n",
        "        result = self.model.transcribe(\n",
        "            audio_path,\n",
        "            language=language,\n",
        "            word_timestamps=word_timestamps,\n",
        "            verbose=False\n",
        "        )\n",
        "\n",
        "        # Format segments\n",
        "        segments = []\n",
        "        for seg in result['segments']:\n",
        "            segment_data = {\n",
        "                'start': float(seg['start']),\n",
        "                'end': float(seg['end']),\n",
        "                'text': seg['text'].strip(),\n",
        "                'words': []\n",
        "            }\n",
        "\n",
        "            if 'words' in seg and seg['words']:\n",
        "                for word in seg['words']:\n",
        "                    segment_data['words'].append({\n",
        "                        'word': word['word'].strip(),\n",
        "                        'start': float(word['start']),\n",
        "                        'end': float(word['end'])\n",
        "                    })\n",
        "\n",
        "            segments.append(segment_data)\n",
        "\n",
        "        print(f\"‚úÖ Transcribed {len(segments)} segments in {result['language']}\")\n",
        "\n",
        "        return {\n",
        "            'language': result['language'],\n",
        "            'text': result['text'].strip(),\n",
        "            'segments': segments\n",
        "        }\n",
        "\n",
        "print(\"‚úÖ MultilingualTranscriber class defined\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0WNmCEZdYD45",
        "outputId": "c46e04e8-ac36-42f1-97cb-474d26e20b19"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ MultilingualTranscriber class defined\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================================================\n",
        "# CELL 4: Multilingual Translator\n",
        "# ============================================================================\n",
        "\n",
        "class MultilingualTranslator:\n",
        "    \"\"\"Translate captions between languages\"\"\"\n",
        "\n",
        "    TRANSLATION_MODELS = {\n",
        "        ('en', 'hi'): 'Helsinki-NLP/opus-mt-en-hi',\n",
        "        ('en', 'es'): 'Helsinki-NLP/opus-mt-en-es',\n",
        "        ('en', 'fr'): 'Helsinki-NLP/opus-mt-en-fr',\n",
        "        ('en', 'de'): 'Helsinki-NLP/opus-mt-en-de',\n",
        "        ('hi', 'en'): 'Helsinki-NLP/opus-mt-hi-en',\n",
        "        ('es', 'en'): 'Helsinki-NLP/opus-mt-es-en',\n",
        "        ('fr', 'en'): 'Helsinki-NLP/opus-mt-fr-en',\n",
        "        ('de', 'en'): 'Helsinki-NLP/opus-mt-de-en',\n",
        "    }\n",
        "\n",
        "    def __init__(self):\n",
        "        self.models = {}\n",
        "        self.tokenizers = {}\n",
        "        self.device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "\n",
        "    def load_model(self, source_lang, target_lang):\n",
        "        \"\"\"Load translation model for language pair\"\"\"\n",
        "        model_key = (source_lang, target_lang)\n",
        "\n",
        "        if model_key in self.models:\n",
        "            return\n",
        "\n",
        "        if model_key not in self.TRANSLATION_MODELS:\n",
        "            raise ValueError(f\"Translation {source_lang}‚Üí{target_lang} not supported\")\n",
        "\n",
        "        model_name = self.TRANSLATION_MODELS[model_key]\n",
        "        print(f\"üì• Loading: {source_lang} ‚Üí {target_lang}\")\n",
        "\n",
        "        self.tokenizers[model_key] = MarianTokenizer.from_pretrained(model_name)\n",
        "        self.models[model_key] = MarianMTModel.from_pretrained(model_name).to(self.device)\n",
        "\n",
        "        print(f\"‚úÖ Model ready\")\n",
        "\n",
        "    def translate_text(self, text, source_lang, target_lang):\n",
        "        \"\"\"Translate single text\"\"\"\n",
        "        if source_lang == target_lang:\n",
        "            return text\n",
        "\n",
        "        model_key = (source_lang, target_lang)\n",
        "\n",
        "        if model_key not in self.models:\n",
        "            self.load_model(source_lang, target_lang)\n",
        "\n",
        "        tokenizer = self.tokenizers[model_key]\n",
        "        model = self.models[model_key]\n",
        "\n",
        "        inputs = tokenizer(text, return_tensors=\"pt\", padding=True).to(self.device)\n",
        "\n",
        "        with torch.no_grad():\n",
        "            translated = model.generate(**inputs)\n",
        "\n",
        "        return tokenizer.decode(translated[0], skip_special_tokens=True)\n",
        "\n",
        "    def translate_segments(self, segments, source_lang, target_lang):\n",
        "        \"\"\"Translate all caption segments\"\"\"\n",
        "        print(f\"üåê Translating {len(segments)} segments: {source_lang} ‚Üí {target_lang}\")\n",
        "\n",
        "        translated = []\n",
        "        for seg in segments:\n",
        "            translated_text = self.translate_text(seg['text'], source_lang, target_lang)\n",
        "\n",
        "            translated_seg = seg.copy()\n",
        "            translated_seg['text'] = translated_text\n",
        "            translated_seg['original_text'] = seg['text']\n",
        "\n",
        "            translated.append(translated_seg)\n",
        "\n",
        "        print(f\"‚úÖ Translation complete\")\n",
        "        return translated\n",
        "\n",
        "print(\"‚úÖ MultilingualTranslator class defined\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G1BsP5nuYKk8",
        "outputId": "12dd4e47-7412-4c2c-d3ad-4bb977a52661"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ MultilingualTranslator class defined\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================================================\n",
        "# CELL 5: Caption File Generator\n",
        "# ============================================================================\n",
        "\n",
        "class CaptionGenerator:\n",
        "    \"\"\"Generate SRT, ASS, VTT caption files\"\"\"\n",
        "\n",
        "    @staticmethod\n",
        "    def format_timestamp_srt(seconds):\n",
        "        \"\"\"Convert to SRT format (HH:MM:SS,mmm)\"\"\"\n",
        "        td = timedelta(seconds=seconds)\n",
        "        hours = int(td.total_seconds() // 3600)\n",
        "        minutes = int((td.total_seconds() % 3600) // 60)\n",
        "        secs = int(td.total_seconds() % 60)\n",
        "        millis = int((td.total_seconds() % 1) * 1000)\n",
        "        return f\"{hours:02d}:{minutes:02d}:{secs:02d},{millis:03d}\"\n",
        "\n",
        "    @staticmethod\n",
        "    def generate_srt(segments, output_path=None):\n",
        "        \"\"\"Generate SRT subtitle file\"\"\"\n",
        "        srt_lines = []\n",
        "\n",
        "        for i, seg in enumerate(segments, 1):\n",
        "            start = CaptionGenerator.format_timestamp_srt(seg['start'])\n",
        "            end = CaptionGenerator.format_timestamp_srt(seg['end'])\n",
        "\n",
        "            srt_lines.append(f\"{i}\")\n",
        "            srt_lines.append(f\"{start} --> {end}\")\n",
        "            srt_lines.append(seg['text'])\n",
        "            srt_lines.append(\"\")\n",
        "\n",
        "        srt_content = \"\\n\".join(srt_lines)\n",
        "\n",
        "        if output_path:\n",
        "            with open(output_path, 'w', encoding='utf-8') as f:\n",
        "                f.write(srt_content)\n",
        "            print(f\"‚úÖ SRT saved: {output_path}\")\n",
        "\n",
        "        return srt_content\n",
        "\n",
        "    @staticmethod\n",
        "    def format_timestamp_ass(seconds):\n",
        "        \"\"\"Convert to ASS format (H:MM:SS.cc)\"\"\"\n",
        "        hours = int(seconds // 3600)\n",
        "        minutes = int((seconds % 3600) // 60)\n",
        "        secs = int(seconds % 60)\n",
        "        centisecs = int((seconds % 1) * 100)\n",
        "        return f\"{hours}:{minutes:02d}:{secs:02d}.{centisecs:02d}\"\n",
        "\n",
        "    @staticmethod\n",
        "    def generate_ass(segments, style='default', output_path=None):\n",
        "        \"\"\"Generate ASS subtitle with styling\"\"\"\n",
        "\n",
        "        styles = {\n",
        "            'default': {\n",
        "                'font': 'Arial Bold', 'size': 24,\n",
        "                'color': '&H00FFFFFF', 'outline': '&H00000000'\n",
        "            },\n",
        "            'tiktok': {\n",
        "                'font': 'Arial Bold', 'size': 28,\n",
        "                'color': '&H00FFFF00', 'outline': '&H00000000'\n",
        "            },\n",
        "            'reels': {\n",
        "                'font': 'Helvetica Bold', 'size': 26,\n",
        "                'color': '&H00FFFFFF', 'outline': '&H00FF6B00'\n",
        "            }\n",
        "        }\n",
        "\n",
        "        s = styles.get(style, styles['default'])\n",
        "\n",
        "        ass_content = f\"\"\"[Script Info]\n",
        "Title: CaptionCrafter AI\n",
        "ScriptType: v4.00+\n",
        "\n",
        "[V4+ Styles]\n",
        "Format: Name, Fontname, Fontsize, PrimaryColour, OutlineColour, Bold, Outline, Shadow, Alignment\n",
        "Style: Default,{s['font']},{s['size']},{s['color']},{s['outline']},-1,3,2,2\n",
        "\n",
        "[Events]\n",
        "Format: Layer, Start, End, Style, Text\n",
        "\"\"\"\n",
        "\n",
        "        for seg in segments:\n",
        "            start = CaptionGenerator.format_timestamp_ass(seg['start'])\n",
        "            end = CaptionGenerator.format_timestamp_ass(seg['end'])\n",
        "            text = seg['text'].replace('\\\\', '\\\\\\\\')\n",
        "\n",
        "            ass_content += f\"Dialogue: 0,{start},{end},Default,{text}\\n\"\n",
        "\n",
        "        if output_path:\n",
        "            with open(output_path, 'w', encoding='utf-8') as f:\n",
        "                f.write(ass_content)\n",
        "            print(f\"‚úÖ ASS saved: {output_path}\")\n",
        "\n",
        "        return ass_content\n",
        "\n",
        "print(\"‚úÖ CaptionGenerator class defined\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FRtZls7GYWlg",
        "outputId": "d847b1d9-f182-4957-f002-d6375ebda076"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ CaptionGenerator class defined\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================================================\n",
        "# CELL 7: File Upload & Processing Functions\n",
        "# ============================================================================\n",
        "\n",
        "def upload_video():\n",
        "    \"\"\"Upload video file to Colab\"\"\"\n",
        "    print(\"üì§ Click 'Choose Files' to upload your video...\")\n",
        "    uploaded = files.upload()\n",
        "\n",
        "    if uploaded:\n",
        "        filename = list(uploaded.keys())[0]\n",
        "        print(f\"‚úÖ Uploaded: {filename}\")\n",
        "        return filename\n",
        "    return None\n",
        "\n",
        "def process_multilingual_video(\n",
        "    video_path,\n",
        "    source_language=None,\n",
        "    target_languages=['en', 'hi', 'es']\n",
        "):\n",
        "    \"\"\"\n",
        "    Complete multilingual caption generation pipeline\n",
        "\n",
        "    Args:\n",
        "        video_path: Path to video file\n",
        "        source_language: Source language (None = auto-detect)\n",
        "        target_languages: List of target language codes\n",
        "\n",
        "    Returns:\n",
        "        Dictionary with captions in all languages\n",
        "    \"\"\"\n",
        "\n",
        "    print(\"\\n\" + \"=\" * 70)\n",
        "    print(\"üé¨ MULTILINGUAL CAPTION GENERATION PIPELINE\")\n",
        "    print(\"=\" * 70)\n",
        "\n",
        "    # Step 1: Transcribe\n",
        "    print(\"\\nüìù Step 1: Transcribing video...\")\n",
        "    if source_language:\n",
        "        result = transcriber.transcribe(video_path, language=source_language)\n",
        "    else:\n",
        "        result = transcriber.transcribe(video_path)\n",
        "\n",
        "    source_lang = result['language']\n",
        "    source_segments = result['segments']\n",
        "\n",
        "    print(f\"‚úÖ Source language: {source_lang}\")\n",
        "    print(f\"‚úÖ Detected {len(source_segments)} segments\")\n",
        "    print(f\"‚úÖ Full text: {result['text'][:200]}...\")\n",
        "\n",
        "    # Step 2: Translate to target languages\n",
        "    all_captions = {source_lang: source_segments}\n",
        "\n",
        "    for target_lang in target_languages:\n",
        "        if target_lang != source_lang:\n",
        "            print(f\"\\nüåê Step 2: Translating to {target_lang}...\")\n",
        "            translated = translator.translate_segments(\n",
        "                source_segments,\n",
        "                source_lang,\n",
        "                target_lang\n",
        "            )\n",
        "            all_captions[target_lang] = translated\n",
        "\n",
        "    # Step 3: Generate caption files\n",
        "    print(\"\\nüìÑ Step 3: Generating caption files...\")\n",
        "    caption_files = {}\n",
        "\n",
        "    for lang, segments in all_captions.items():\n",
        "        srt_file = f\"captions_{lang}.srt\"\n",
        "        CaptionGenerator.generate_srt(segments, srt_file)\n",
        "        caption_files[lang] = srt_file\n",
        "\n",
        "    print(\"\\n\" + \"=\" * 70)\n",
        "    print(\"‚úÖ PROCESSING COMPLETE!\")\n",
        "    print(\"=\" * 70)\n",
        "\n",
        "    return {\n",
        "        'source_language': source_lang,\n",
        "        'captions': all_captions,\n",
        "        'caption_files': caption_files,\n",
        "        'text': result['text']\n",
        "    }\n",
        "\n",
        "print(\"‚úÖ Processing functions defined\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FnH14mvvYb9V",
        "outputId": "09f36368-2c1c-4e22-893b-fd3ef198da09"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ Processing functions defined\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================================================\n",
        "# CELL 8: QUICK TEST - Upload and Process\n",
        "# ============================================================================\n",
        "\n",
        "# Initialize the transcriber and translator\n",
        "transcriber = MultilingualTranscriber()\n",
        "translator = MultilingualTranslator()\n",
        "\n",
        "# Upload your video\n",
        "video_file = upload_video()\n",
        "\n",
        "if video_file:\n",
        "    # Process video with multilingual captions\n",
        "    results = process_multilingual_video(\n",
        "        video_file,\n",
        "        source_language=None,  # Auto-detect\n",
        "        target_languages=['en', 'hi', 'es']  # English, Hindi, Spanish\n",
        "    )\n",
        "\n",
        "    # Display results\n",
        "    print(\"\\nüìä RESULTS:\")\n",
        "    print(\"=\" * 70)\n",
        "    print(f\"Source Language: {results['source_language']}\")\n",
        "    print(f\"\\nFull Text:\\n{results['text']}\\n\")\n",
        "\n",
        "    # Show captions in each language\n",
        "    for lang, segments in results['captions'].items():\n",
        "        print(f\"\\n{lang.upper()} CAPTIONS:\")\n",
        "        print(\"-\" * 70)\n",
        "        for seg in segments[:3]:  # Show first 3 segments\n",
        "            print(f\"[{seg['start']:.1f}s - {seg['end']:.1f}s] {seg['text']}\")\n",
        "\n",
        "    # Download caption files\n",
        "    print(\"\\nüì• Downloading caption files...\")\n",
        "    for lang, filepath in results['caption_files'].items():\n",
        "        files.download(filepath)\n",
        "        print(f\"‚úÖ Downloaded: {filepath}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 125
        },
        "id": "q1vcdwOnYknq",
        "outputId": "f6c5331d-3713-4503-b125-f838f8cdfbdd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üîÑ Loading Whisper 'base' model...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 139M/139M [00:01<00:00, 125MiB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ Model loaded on cpu\n",
            "üì§ Click 'Choose Files' to upload your video...\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-3afc9e77-92b6-4a09-9ecf-640a61d0181c\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-3afc9e77-92b6-4a09-9ecf-640a61d0181c\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================================================\n",
        "# CELL 7: File Upload & Processing Functions\n",
        "# ============================================================================\n",
        "\n",
        "def upload_video():\n",
        "    \"\"\"Upload video file to Colab\"\"\"\n",
        "    print(\"üì§ Click 'Choose Files' to upload your video...\")\n",
        "    uploaded = files.upload()\n",
        "\n",
        "    if uploaded:\n",
        "        filename = list(uploaded.keys())[0]\n",
        "        print(f\"‚úÖ Uploaded: {filename}\")\n",
        "        return filename\n",
        "    return None\n",
        "\n",
        "def process_multilingual_video(\n",
        "    video_path,\n",
        "    source_language=None,\n",
        "    target_languages=['en', 'hi', 'es']\n",
        "):\n",
        "    \"\"\"\n",
        "    Complete multilingual caption generation pipeline\n",
        "\n",
        "    Args:\n",
        "        video_path: Path to video file\n",
        "        source_language: Source language (None = auto-detect)\n",
        "        target_languages: List of target language codes\n",
        "\n",
        "    Returns:\n",
        "        Dictionary with captions in all languages\n",
        "    \"\"\"\n",
        "\n",
        "    print(\"\\n\" + \"=\" * 70)\n",
        "    print(\"üé¨ MULTILINGUAL CAPTION GENERATION PIPELINE\")\n",
        "    print(\"=\" * 70)\n",
        "\n",
        "    # Step 1: Transcribe\n",
        "    print(\"\\nüìù Step 1: Transcribing video...\")\n",
        "    if source_language:\n",
        "        result = transcriber.transcribe(video_path, language=source_language)\n",
        "    else:\n",
        "        result = transcriber.transcribe(video_path)\n",
        "\n",
        "    source_lang = result['language']\n",
        "    source_segments = result['segments']\n",
        "\n",
        "    print(f\"‚úÖ Source language: {source_lang}\")\n",
        "    print(f\"‚úÖ Detected {len(source_segments)} segments\")\n",
        "    print(f\"‚úÖ Full text: {result['text'][:200]}...\")\n",
        "\n",
        "    # Step 2: Translate to target languages\n",
        "    all_captions = {source_lang: source_segments}\n",
        "\n",
        "    for target_lang in target_languages:\n",
        "        if target_lang != source_lang:\n",
        "            print(f\"\\nüåê Step 2: Translating to {target_lang}...\")\n",
        "            translated = translator.translate_segments(\n",
        "                source_segments,\n",
        "                source_lang,\n",
        "                target_lang\n",
        "            )\n",
        "            all_captions[target_lang] = translated\n",
        "\n",
        "    # Step 3: Generate caption files\n",
        "    print(\"\\nüìÑ Step 3: Generating caption files...\")\n",
        "    caption_files = {}\n",
        "\n",
        "    for lang, segments in all_captions.items():\n",
        "        srt_file = f\"captions_{lang}.srt\"\n",
        "        CaptionGenerator.generate_srt(segments, srt_file)\n",
        "        caption_files[lang] = srt_file\n",
        "\n",
        "    print(\"\\n\" + \"=\" * 70)\n",
        "    print(\"‚úÖ PROCESSING COMPLETE!\")\n",
        "    print(\"=\" * 70)\n",
        "\n",
        "    return {\n",
        "        'source_language': source_lang,\n",
        "        'captions': all_captions,\n",
        "        'caption_files': caption_files,\n",
        "        'text': result['text']\n",
        "    }\n",
        "\n",
        "# ============================================================================\n",
        "# CELL 8: QUICK TEST - Upload and Process\n",
        "# ============================================================================\n",
        "\n",
        "# Initialize the transcriber and translator\n",
        "transcriber = MultilingualTranscriber()\n",
        "translator = MultilingualTranslator()\n",
        "\n",
        "# Upload your video\n",
        "video_file = upload_video()\n",
        "\n",
        "if video_file:\n",
        "    # Process video with multilingual captions\n",
        "    results = process_multilingual_video(\n",
        "        video_file,\n",
        "        source_language=None,  # Auto-detect\n",
        "        target_languages=['en', 'hi', 'es']  # English, Hindi, Spanish\n",
        "    )\n",
        "\n",
        "    # Display results\n",
        "    print(\"\\nüìä RESULTS:\")\n",
        "    print(\"=\" * 70)\n",
        "    print(f\"Source Language: {results['source_language']}\")\n",
        "    print(f\"\\nFull Text:\\n{results['text']}\\n\")\n",
        "\n",
        "    # Show captions in each language\n",
        "    for lang, segments in results['captions'].items():\n",
        "        print(f\"\\n{lang.upper()} CAPTIONS:\")\n",
        "        print(\"-\" * 70)\n",
        "        for seg in segments[:3]:  # Show first 3 segments\n",
        "            print(f\"[{seg['start']:.1f}s - {seg['end']:.1f}s] {seg['text']}\")\n",
        "\n",
        "    # Download caption files\n",
        "    print(\"\\nüì• Downloading caption files...\")\n",
        "    for lang, filepath in results['caption_files'].items():\n",
        "        files.download(filepath)\n",
        "        print(f\"‚úÖ Downloaded: {filepath}\")"
      ],
      "metadata": {
        "id": "fQc-caO51S_y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================================================\n",
        "# CELL 9: ADVANCED GRADIO UI (With Burned Caption Video Preview)\n",
        "# ============================================================================\n",
        "\n",
        "import os, ffmpeg, gradio as gr\n",
        "\n",
        "def burn_captions(video_path, segments, lang='en', style='default'):\n",
        "    \"\"\"Burn captions into a copy of the video using FFmpeg\"\"\"\n",
        "    if not video_path or not os.path.exists(video_path):\n",
        "        return None\n",
        "\n",
        "    # Create subtitle file\n",
        "    srt_file = f\"captions_{lang}.srt\"\n",
        "    CaptionGenerator.generate_srt(segments, srt_file)\n",
        "\n",
        "    output_path = f\"captioned_{lang}_{os.path.basename(video_path)}\"\n",
        "\n",
        "    # Run FFmpeg subtitle burn-in process\n",
        "    try:\n",
        "        (\n",
        "            ffmpeg\n",
        "            .input(video_path)\n",
        "            .output(output_path, vf=f\"subtitles={srt_file}\", vcodec='libx264', acodec='aac', preset='ultrafast')\n",
        "            .overwrite_output()\n",
        "            .run(quiet=True)\n",
        "        )\n",
        "        print(f\"‚úÖ Burned subtitles into video: {output_path}\")\n",
        "        return output_path\n",
        "    except ffmpeg.Error as e:\n",
        "        print(\"‚ùå FFmpeg Error:\", e)\n",
        "        return None\n",
        "\n",
        "\n",
        "def gradio_process(video_path, target_langs_str):\n",
        "    \"\"\"Process uploaded video via Gradio interface\"\"\"\n",
        "\n",
        "    if not video_path or not os.path.exists(video_path):\n",
        "        return \"Please upload a valid video.\", \"\", \"\", \"\", None\n",
        "\n",
        "    print(f\"üìÅ Processing file: {video_path}\")\n",
        "    target_langs = [lang.strip() for lang in target_langs_str.split(',') if lang.strip()]\n",
        "\n",
        "    # Transcribe + translate\n",
        "    results = process_multilingual_video(\n",
        "        video_path,\n",
        "        source_language=None,\n",
        "        target_languages=target_langs\n",
        "    )\n",
        "\n",
        "    source_lang = results['source_language']\n",
        "    captions_preview = f\"### Detected Source Language: **{source_lang.upper()}**\\n\\n\"\n",
        "\n",
        "    for lang in target_langs:\n",
        "        if lang in results['captions']:\n",
        "            captions_preview += f\"#### {lang.upper()} Captions\\n\"\n",
        "            for seg in results['captions'][lang][:5]:\n",
        "                captions_preview += f\"- [{seg['start']:.1f}-{seg['end']:.1f}s] {seg['text']}\\n\"\n",
        "            captions_preview += \"\\n\"\n",
        "\n",
        "    # Create caption SRT files and burned video\n",
        "    srt_files = []\n",
        "    video_with_captions = None\n",
        "    first_lang = target_langs[0] if target_langs else source_lang\n",
        "\n",
        "    if first_lang in results['captions']:\n",
        "        CaptionGenerator.generate_srt(results['captions'][first_lang], f\"captions_{first_lang}.srt\")\n",
        "        srt_files.append(f\"captions_{first_lang}.srt\")\n",
        "\n",
        "        # Burn captions into video (preview)\n",
        "        video_with_captions = burn_captions(video_path, results['captions'][first_lang], first_lang)\n",
        "\n",
        "\n",
        "    # Update outputs to match the new function signature and ensure correct data is returned\n",
        "    return (\n",
        "        captions_preview,\n",
        "        results['text'],\n",
        "        srt_files[0] if srt_files else None,\n",
        "        source_lang,\n",
        "        video_with_captions\n",
        "    )\n",
        "\n",
        "\n",
        "# BUILD INTERFACE\n",
        "demo = gr.Interface(\n",
        "    fn=gradio_process,\n",
        "    inputs=[\n",
        "        gr.Video(label=\"üé• Upload Video\"),\n",
        "        gr.Textbox(label=\"üåê Target Languages (comma-separated)\", value=\"en,hi,es\")\n",
        "    ],\n",
        "    outputs=[\n",
        "        gr.Markdown(label=\"üìù Captions Preview\"),\n",
        "        gr.Textbox(label=\"üìÑ Full Transcript\"),\n",
        "        gr.File(label=\"‚¨áÔ∏è Download SRT File\"),\n",
        "        gr.Textbox(label=\"Detected Source Language\"),\n",
        "        gr.Video(label=\"üé¨ Captioned Video Preview\")  # new output component\n",
        "    ],\n",
        "    title=\"üé¨ CaptionCrafter AI ‚Äì Multilingual Caption Generator\",\n",
        "    description=\"\"\"\n",
        "Upload a short video, and this tool automatically transcribes, translates,\n",
        "and generates captions in multiple languages. It also burns captions\n",
        "into the video for live preview.\n",
        "\n",
        "**Supports:** English (en), Hindi (hi), Spanish (es), French (fr), German (de).\n",
        "\"\"\",\n",
        "    examples=[\n",
        "        [None, \"en,hi,es\"],\n",
        "        [None, \"en,fr\"]\n",
        "    ]\n",
        ")\n",
        "\n",
        "print(\"\\nüöÄ Launching Advanced Gradio Interface with Video Preview...\")\n",
        "print(\"=\" * 70)\n",
        "demo.launch(share=True)"
      ],
      "metadata": {
        "id": "h6163HTSFCTY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================================================\n",
        "# CELL 10: BATCH PROCESSING - Multiple Videos\n",
        "# ============================================================================\n",
        "\n",
        "def batch_process_videos(video_paths, target_languages=['en', 'hi', 'es']):\n",
        "    \"\"\"Process multiple videos at once\"\"\"\n",
        "\n",
        "    all_results = []\n",
        "\n",
        "    for i, video_path in enumerate(video_paths, 1):\n",
        "        print(f\"\\n{'='*70}\")\n",
        "        print(f\"Processing Video {i}/{len(video_paths)}: {video_path}\")\n",
        "        print(f\"{'='*70}\")\n",
        "\n",
        "        result = process_multilingual_video(\n",
        "            video_path,\n",
        "            target_languages=target_languages\n",
        "        )\n",
        "\n",
        "        all_results.append({\n",
        "            'filename': video_path,\n",
        "            'results': result\n",
        "        })\n",
        "\n",
        "    return all_results\n",
        "\n",
        "# Example: Upload multiple videos\n",
        "print(\"üì§ Upload multiple videos for batch processing...\")\n",
        "uploaded_files = files.upload()\n",
        "\n",
        "if uploaded_files:\n",
        "    video_list = list(uploaded_files.keys())\n",
        "\n",
        "    batch_results = batch_process_videos(\n",
        "        video_list,\n",
        "        target_languages=['en', 'hi', 'es']\n",
        "    )\n",
        "\n",
        "    print(\"\\n‚úÖ Batch processing complete!\")\n",
        "    print(f\"Processed {len(batch_results)} videos\")\n"
      ],
      "metadata": {
        "id": "ocPr9wDAFy-i"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================================================\n",
        "# CELL 11: BURN CAPTIONS INTO VIDEO (using FFmpeg)\n",
        "# ============================================================================\n",
        "\n",
        "def burn_captions_to_video(video_path, segments, language, output_path=None):\n",
        "    \"\"\"\n",
        "    Burn captions directly into video using FFmpeg\n",
        "\n",
        "    Args:\n",
        "        video_path: Input video path\n",
        "        segments: Caption segments\n",
        "        language: Language code\n",
        "        output_path: Output video path\n",
        "    \"\"\"\n",
        "\n",
        "    if output_path is None:\n",
        "        output_path = f\"captioned_{language}_{os.path.basename(video_path)}\"\n",
        "\n",
        "    # Generate ASS subtitle file\n",
        "    ass_file = f\"subtitles_{language}.ass\"\n",
        "    CaptionGenerator.generate_ass(segments, 'tiktok', ass_file)\n",
        "\n",
        "    print(f\"üé¨ Burning {language} captions into video...\")\n",
        "\n",
        "    # Use FFmpeg to burn subtitles\n",
        "    input_video = ffmpeg.input(video_path)\n",
        "\n",
        "    video = input_video.video.filter('ass', ass_file)\n",
        "    audio = input_video.audio\n",
        "\n",
        "    output = ffmpeg.output(\n",
        "        video,\n",
        "        audio,\n",
        "        output_path,\n",
        "        vcodec='libx264',\n",
        "        acodec='aac',\n",
        "        preset='ultrafast'\n",
        "    )\n",
        "\n",
        "    ffmpeg.run(output, overwrite_output=True, quiet=True)\n",
        "\n",
        "    print(f\"‚úÖ Captioned video saved: {output_path}\")\n",
        "\n",
        "    return output_path\n",
        "\n",
        "# Example usage\n",
        "if video_file and results:\n",
        "    # Burn English captions\n",
        "    captioned_video = burn_captions_to_video(\n",
        "        video_file,\n",
        "        results['captions']['en'],\n",
        "        'en'\n",
        "    )\n",
        "\n",
        "    # Display result\n",
        "    display(Video(captioned_video, embed=True))\n",
        "\n",
        "    # Download\n",
        "    files.download(captioned_video)\n"
      ],
      "metadata": {
        "id": "CVHn7SyVIA1p"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================================================\n",
        "# CELL 12: EXPORT ALL RESULTS TO ZIP\n",
        "# ============================================================================\n",
        "\n",
        "import zipfile\n",
        "\n",
        "def create_export_package(results, video_filename):\n",
        "    \"\"\"Create a ZIP file with all outputs\"\"\"\n",
        "\n",
        "    zip_filename = f\"captions_{os.path.splitext(video_filename)[0]}.zip\"\n",
        "\n",
        "    with zipfile.ZipFile(zip_filename, 'w') as zipf:\n",
        "        # Add caption files\n",
        "        for lang, filepath in results['caption_files'].items():\n",
        "            if os.path.exists(filepath):\n",
        "                zipf.write(filepath)\n",
        "\n",
        "        # Add JSON with full results\n",
        "        json_file = 'results.json'\n",
        "        with open(json_file, 'w', encoding='utf-8') as f:\n",
        "            json.dump({\n",
        "                'source_language': results['source_language'],\n",
        "                'text': results['text'],\n",
        "                'captions': {\n",
        "                    lang: [{\n",
        "                        'start': seg['start'],\n",
        "                        'end': seg['end'],\n",
        "                        'text': seg['text']\n",
        "                    } for seg in segments]\n",
        "                    for lang, segments in results['captions'].items()\n",
        "                }\n",
        "            }, f, indent=2, ensure_ascii=False)\n",
        "\n",
        "        zipf.write(json_file)\n",
        "\n",
        "    print(f\"‚úÖ Export package created: {zip_filename}\")\n",
        "    return zip_filename\n",
        "\n",
        "# Create and download export package\n",
        "if video_file and results:\n",
        "    export_zip = create_export_package(results, video_file)\n",
        "    files.download(export_zip)\n"
      ],
      "metadata": {
        "id": "fN0JpB-7JD_3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================================================\n",
        "# CELL 13: PERFORMANCE MONITORING\n",
        "# ============================================================================\n",
        "\n",
        "import time\n",
        "\n",
        "def benchmark_processing(video_path, target_languages=['en', 'hi', 'es']):\n",
        "    \"\"\"Measure processing performance\"\"\"\n",
        "\n",
        "    timings = {}\n",
        "\n",
        "    # Transcription\n",
        "    start = time.time()\n",
        "    result = transcriber.transcribe(video_path)\n",
        "    timings['transcription'] = time.time() - start\n",
        "\n",
        "    # Translation\n",
        "    translation_times = {}\n",
        "    for target_lang in target_languages:\n",
        "        if target_lang != result['language']:\n",
        "            start = time.time()\n",
        "            translator.translate_segments(\n",
        "                result['segments'],\n",
        "                result['language'],\n",
        "                target_lang\n",
        "            )\n",
        "            translation_times[target_lang] = time.time() - start\n",
        "\n",
        "    timings['translation'] = translation_times\n",
        "\n",
        "    # Print report\n",
        "    print(\"\\n‚è±Ô∏è  PERFORMANCE REPORT\")\n",
        "    print(\"=\" * 70)\n",
        "    print(f\"Transcription: {timings['transcription']:.2f}s\")\n",
        "    for lang, t in translation_times.items():\n",
        "        print(f\"Translation to {lang}: {t:.2f}s\")\n",
        "    print(f\"Total: {timings['transcription'] + sum(translation_times.values()):.2f}s\")\n",
        "    print(\"=\" * 70)\n",
        "\n",
        "    return timings\n",
        "\n",
        "# Run benchmark\n",
        "if video_file:\n",
        "    benchmark_processing(video_file, ['en', 'hi', 'es'])\n"
      ],
      "metadata": {
        "id": "Wiy9rMXHJTmN"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}